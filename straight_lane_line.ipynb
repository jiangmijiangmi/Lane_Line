{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#彩色图均衡化看看有什么变化\n",
    "\n",
    "def ImageHe(img):\n",
    "\n",
    "    clahe=cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))\n",
    "\n",
    "    r,b,g=cv2.split(img)\n",
    "    rh=clahe.apply(r)\n",
    "    bh=clahe.apply(b)\n",
    "    gh=clahe.apply(g)\n",
    "\n",
    "    img_new=cv2.merge((rh,bh,gh))\n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#边缘检测\n",
    "\n",
    "def EdgeDetect(img):\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    edges=cv2.Canny(blur,100,200)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选取兴趣区域\n",
    "\n",
    "def RegionOfIn(img):\n",
    "    w,h=img.shape[0],img.shape[1]\n",
    "    mask=np.zeros_like(img)\n",
    "    if len(img.shape)>2: \n",
    "        mask_color=(255,)*img.shape[2]\n",
    "    else:\n",
    "        mask_color=(255,)\n",
    "    \n",
    "    vertices=np.array([[(0,w),(580,300),(600,300),(h,w)]])\n",
    "    \n",
    "    cv2.fillPoly(mask,vertices,mask_color)\n",
    "\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制直线\n",
    "def findpoint(lines,ymax):\n",
    "    x=[p[0][0] for p in lines]\n",
    "    y=[p[0][1] for p in lines]\n",
    "    a,b = np.polyfit(y,x,1)\n",
    "    xmax=int(a*ymax+b)\n",
    "    return xmax,a,b\n",
    "\n",
    "    \n",
    "def hough_lines(img, min_line_len,max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, 1, np.pi/180, 20, minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    right_lines=[]\n",
    "    left_lines=[]\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if x1!=x2:\n",
    "                k=(y2-y1)/(x2-x1)\n",
    "                if k>0.3:\n",
    "                    right_lines.append([(x1,y1)])\n",
    "                    right_lines.append([(x2,y2)])\n",
    "                elif k<0:\n",
    "                    left_lines.append([(x1,y1)])\n",
    "                    left_lines.append([(x2,y2)])\n",
    "    if (len(left_lines) <= 0 or len(right_lines) <= 0):\n",
    "        return line_img\n",
    "    ymax=img.shape[0]\n",
    "    right_max,a_1,b_1=findpoint(right_lines,ymax)\n",
    "    left_max,a_2,b_2=findpoint(left_lines,ymax)\n",
    "    midpoint_y=int((b_2-b_1)/(a_1-a_2))\n",
    "    midpoint_x=int(a_1*midpoint_y+b_1)\n",
    "    cv2.line(line_img,(midpoint_x,midpoint_y),(right_max,ymax),(255,0,0),10)\n",
    "    cv2.line(line_img,(midpoint_x,midpoint_y),(left_max,ymax),(255,0,0),10)\n",
    "    \n",
    "    return line_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#融合图像\n",
    "\n",
    "def weighted_img(img1,img2, a=0.8,b=1.):\n",
    "    return cv2.addWeighted(img2,a,img1,b,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img):\n",
    "    img_new=ImageHe(img)\n",
    "    edge_img=EdgeDetect(img_new)\n",
    "    edge_cut_img=RegionOfIn(edge_img)\n",
    "    line_img=hough_lines(edge_cut_img,20,20)\n",
    "    final_img=weighted_img(line_img,img)\n",
    "    \n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('solidWhiteRight.mp4')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame=process_img(frame)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= np.array(Image.open('sample_color.jpg'))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(process_img(img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
